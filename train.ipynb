{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We will train the network and save the model to disk. We will use this model in the `predict.ipynb` notebook.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "We are currently using tensorflow 2.0 which is currently in beta state. So it is expected and ok that there are warnings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries and set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "import bodestm.util as util\n",
    "import gitignored.config as cfg\n",
    "\n",
    "n_examples_per_class = 30\n",
    "IMG_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "normalize = False\n",
    "use_class_weight = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load classification\n",
    "\n",
    "Load the classification of the training images into a training and an evaluating data frame. There should be one classification file per folder with training images. The folder must have the same name as the classification file without the file extension. The images in the folder must be named exactly like in the classification file. There can be multiple classification files and folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_files = glob.glob(\"gitignored/classified_images/*.txt\")\n",
    "pd.DataFrame({\"classification_files\": classification_files}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes in the classification file are `[0,1,3,4,5,6]`. Note, that there is no class `2`. This nomenclature is called `ext_label` below. The scientists are using this nomenclature to do checks and they will use it for further data analysis. We will use our own nomenclature that has the classes `[0,1,2,3,4,5]`. We shifted the classes `[3,4,5,6]`, so our classes are incrementing by 1. This is necessary to use the TensorFlow libraries. We call this nomenclature `int_label` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = util.get_classification_df(classification_files)\n",
    "print(len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set in training and evaluating data sets. In the evaluating data set, there will be `n_examples_per_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_eval = util.split_data_set_in_train_and_eval(df, n_examples_per_class)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check, if the evaluation data set contains `n_examples_per_class` and is evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.groupby(\"int_label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the balance of the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show_balance = df_train.groupby(\"int_label\").count()\n",
    "print(df_show_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data set is heavily unbalanced. To make the predictions also accurate for the minority classes, one can use a weighted loss function. If `use_class_weight`, we will calculate a weight for each class.\n",
    "\n",
    "If $w_i$ is the weight for a class $c_i$ and there are $n_i$ images for that class,\n",
    "\n",
    "$w_i \\cdot n_i = w_j \\cdot n_j$\n",
    "\n",
    "for every $i,j \\in [0,1,2,3,4,5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_class_weight:\n",
    "    class_weight = util.get_class_weights_map(df_show_balance)\n",
    "else:\n",
    "    class_weight = None\n",
    "    \n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exporting the data to tfrecods files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"exporting eval data set with {} records\".format(len(df_eval)))\n",
    "util.export_dataframe(df_eval, cfg.path_to_eval_data_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"exporting training data set with {} records\".format(len(df_train)))\n",
    "util.export_dataframe(df_train, cfg.path_to_train_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training of the model\n",
    "\n",
    "Here we are training the model. The training can be observed by using a TensorBoard. Keras will check the evaluation loss and accuracy after each epoch. It will save the model weights if the evaluation loss is smaller than the previous one. After the training is done, the best weights are loaded and the model is saved to disk.\n",
    "\n",
    "**Important:** Make sure to use the most recent `model.h5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(input_shape=(128, 128, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(6, activation='softmax', name='predictions')\n",
    "])\n",
    "\n",
    "# default values for adam optimizer\n",
    "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# see: https://keras.io/optimizers/\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = cfg.gitignored_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=cfg.path_to_checkpoints, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    tf.data.TFRecordDataset(cfg.path_to_train_data).map(util.parse_tfrecord).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE),\n",
    "    validation_data=tf.data.TFRecordDataset(cfg.path_to_eval_data).map(util.parse_tfrecord).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE),\n",
    "    epochs=40,\n",
    "    callbacks=tensorboard_callback,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "# load weights for the best metrics (currently loss)\n",
    "model.load_weights(cfg.path_to_checkpoints)\n",
    "model.save(cfg.gitignored_path + \"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the accuracy per class\n",
    "\n",
    "For our aim to classify also the minority classes well, we have to check not only the total accuracy, but also the accuracy per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    tf.data.TFRecordDataset(cfg.path_to_eval_data).map(util.parse_tfrecord).batch(32),\n",
    "    batch_size=None\n",
    ")\n",
    "print(\"shape of predictions: {}\".format(predictions.shape))\n",
    "print('succesfully predicted {} images'.format(len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(cfg.path_to_eval_data).map(util.parse_tfrecord)\n",
    "parsed_records = [parsed_record for parsed_record in ds.take(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "class_predictions = []\n",
    "max_probs = []\n",
    "i = 0\n",
    "\n",
    "for parsed_record in parsed_records:\n",
    "    labels.append(parsed_record[1].numpy())\n",
    "    class_predictions.append(np.argmax(predictions[i]))\n",
    "    max_probs.append(np.max(predictions[i]))\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    \"int_label\": labels,\n",
    "    \"class_prediction\": class_predictions,\n",
    "    \"0_prediction\" : predictions.T[0],\n",
    "    \"1_prediction\" : predictions.T[1],\n",
    "    \"2_prediction\" : predictions.T[2],\n",
    "    \"3_prediction\" : predictions.T[3],\n",
    "    \"4_prediction\" : predictions.T[4],\n",
    "    \"5_prediction\" : predictions.T[5],\n",
    "    \"prob\": max_probs\n",
    "})\n",
    "\n",
    "df_predictions[\"ext_label\"] = util.remap_cross_back(df_predictions.int_label)\n",
    "\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy per class\n",
    "for i in range(6):\n",
    "    with_class_prediction = df_predictions[df_predictions[\"class_prediction\"]==i]\n",
    "    hits = len(with_class_prediction[with_class_prediction[\"int_label\"]==i])\n",
    "    all_of_class = len(df_predictions[df_predictions[\"int_label\"]==i])\n",
    "    print(\"accuracy for class {}: {}\".format(i, hits/all_of_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the certainty per class\n",
    "\n",
    "We have to check the overall certainty distribution and the certainty distribution of the individual classes. If there is a correlation between wrongly classified images and a low certainty of the network, we could use this as a selector for candidates for a double check by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob distribution\n",
    "plt.hist(df_predictions.prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob distribution for single class\n",
    "for cl in [0,1,2,3,4,5]:\n",
    "    plt.hist(df_predictions[df_predictions[\"class_prediction\"] == cl].prob)\n",
    "    plt.title(\"certainty distribution for class {}\".format(cl))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot a few examples\n",
    "\n",
    "We are plotting a few examples, so the scientists can do a brief manual sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some samples\n",
    "rows = 4\n",
    "cols = 4\n",
    "idx = 1\n",
    "\n",
    "ax = None\n",
    "fig = plt.figure(figsize=(cols * 4, rows * 3))\n",
    "for i in range(len(parsed_records[:16])):\n",
    "    parsed_record = parsed_records[i]\n",
    "    ax = fig.add_subplot(rows, cols, idx)\n",
    "    img = parsed_record[0]\n",
    "    img = np.squeeze(img)\n",
    "    int_label = df_predictions.int_label[i]\n",
    "    ext_label = df_predictions.ext_label[i]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"label {} (int {})\".format(ext_label, int_label))\n",
    "    ax.set_xlabel(\"prediction (int): {}\".format(np.argmax(predictions[idx-1])))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    idx += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the certainty distribution for wrongly classified images\n",
    "\n",
    "Here we can check the hypothesis that there is a correlation between wrongly classified images and a low certainty of the network by plotting the certainty distribution for wrongly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrongly_classified = df_predictions[df_predictions[\"class_prediction\"] != df_predictions[\"int_label\"]]\n",
    "df_wrongly_classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_wrongly_classified.prob)\n",
    "plt.title(\"certainty distribution for wrongly classified images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
